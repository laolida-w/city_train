llamafactory-cli train \
  --stage sft \                        
  --model_name_or_path /home/wyh/dataset/models/swift/llava-1.5-7b-hf \
  --do_train \
  --dataset multi_task_data.json \      # 训练多任务数据
  --image_folder /home/wyh/code/images \            # 图片所在文件夹
  --template llava \                    
  --finetuning_type qlora \             # 使用 QLoRA（4-bit 量化）
  --lora_target q_proj,v_proj \         
  --output_dir output/multi_task \   
  --per_device_train_batch_size 1 \     # 适配显存
  --gradient_accumulation_steps 8 \     # 梯度累积
  --num_train_epochs 1 \                # 训练 1 轮
  --save_steps 500 \                     
  --learning_rate 5e-5 \                
  --fp16                                # 使用 FP16 提高效率